# ğŸ§  MindBoard â€“ Hands-Free Communication for the Speech & Motor Impaired

MindBoard is an AI-powered, real-time communication system that enables individuals with speech or motor disabilities to express themselves using nothing but **nose movement** and a **webcam**. The system allows users to type, speak, and participate in live **Google Meet or Zoom meetings**, with no external hardware.

---

## ğŸš€ Features

### âœ… Core Functionalities
- **Nose-based Grid Navigation:** Select letters using head/nose movement.
- **Dwell-based Selection:** Auto-select letters after hovering for 1.5 seconds.
- **Dynamic Subgrid System:** Navigate a 3x3 parent grid and select from letter subgrids.
- **Sentence Construction:** Build full phrases using intuitive zone-based typing.
- **Text-to-Speech Support:** Automatically speak typed sentences.
- **Standalone ML Version:** Includes predictive text using HuggingFace (optional).
- **Google Meet Integration:** Works via OBS Virtual Camera.

### ğŸ§  Accessibility Impact
- Designed for users with ALS, cerebral palsy, spinal cord injuries, and stroke survivors.
- No keyboard, no mouse, no voice required.

---

## ğŸ–¥ï¸ Modes of Use

### ğŸ”¹ Real-Time Google Meet Mode
Control a virtual camera feed via OpenCV, stream it to OBS, and share directly in Google Meet.

### ğŸ”¹ Standalone Mode
Use the grid system with optional ML prediction and text-to-speech offline.

---

## ğŸ”§ Tech Stack

- **Frontend/UI:** OpenCV + Python overlay
- **CV & Tracking:** MediaPipe FaceMesh
- **Integration:** OBS Studio + Virtual Camera
- **Speech:** pyttsx3 (offline TTS)
- **ML (Optional):** HuggingFace Transformers
- **Virtual Camera (Alt):** pyvirtualcam

---

## ğŸ› ï¸ Installation Instructions

### ğŸ“Œ 1. Clone the Repository

```bash
git clone https://github.com/your-repo/mindboard.git
cd mindboard
ğŸ“Œ 2. Set Up Environment
bash
Always show details

Copy
pip install -r requirements.txt
If requirements.txt is not provided, manually install:

bash
Always show details

Copy
pip install opencv-python mediapipe pyttsx3 pyvirtualcam
For ML prediction:

bash
Always show details

Copy
pip install transformers
ğŸ“Œ 3. Install OBS Studio
Download OBS Studio

Install OBS Virtual Camera

Open OBS â†’ Click â€œStart Virtual Cameraâ€

ğŸ“Œ 4. Google Meet Integration
Run your mindboard_meet.py script (or main_meet_mode.py).

In OBS:

Add Window Capture â†’ Select the MindBoard window.

Start Virtual Camera.

In Google Meet:

Go to Settings â†’ Video â†’ Choose OBS Virtual Camera.

You're now speaking via webcam input and nose-based navigation.

ğŸ§  Project Architecture
scss
Always show details

Copy
Webcam â†’ MediaPipe â†’ Nose Tip Tracker
       â†“
   Grid Zone Detection (3x3)
       â†“
Dwell Selector â†’ Sentence Builder
       â†“         â†˜
   TTS (pyttsx3)  ML Prediction (HuggingFace)
       â†“
OpenCV Window â†’ OBS Studio â†’ Google Meet
ğŸ§ª How to Run (All Modes)
â–¶ï¸ Meet Mode (OBS + Virtual Cam)
bash
Always show details

Copy
python mindboard_meet.py
â–¶ï¸ Standalone Offline Mode
bash
Always show details

Copy
python mindboard_standalone.py
This version uses predictive models (optional), speaks via pyttsx3, and runs fully offline.

ğŸ“‚ File Structure
bash
Always show details

Copy
mindboard/
â”œâ”€â”€ mindboard_meet.py             # Google Meet integration version
â”œâ”€â”€ mindboard_standalone.py       # Offline ML + TTS version
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ assets/                       # Icons, visuals, or ML files
ğŸ›¡ï¸ Known Issues & Mitigations
Issue	Fix/Strategy
OBS not detected in Meet	Ensure Virtual Camera is started in OBS
Webcam conflict	Close all other apps using the webcam
Gaze detection unstable	Switched to nose tip tracking for reliability
Auto-selection too fast	Adjustable dwell timer in script (default: 1.5s)

ğŸ§  Why This Matters
Over 1.3 billion people globally live with some form of disability. MindBoard removes one of the most essential barriers â€” communication â€” using only a webcam and intelligent software. No installation, no hardware, just possibility.

ğŸ“ Contact & Credits
Made with â¤ï¸ by Gopesh Bajaj
For hackathons, accessibility research, and real-world deployment.

ğŸ License
MIT License â€“ Free to use, modify, and distribute.
